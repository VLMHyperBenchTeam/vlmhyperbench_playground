# Architecture Decision Records (ARD)

Этот документ фиксирует ключевые архитектурные решения, принятые при проектировании VLMHyperBench.

## ADR-001: Микросервисная архитектура и изоляция окружений

### Контекст
VLMHyperBench должен поддерживать оценку множества различных моделей (HuggingFace, vLLM, SGLang) и метрик. Разные модели могут требовать конфликтующих версий библиотек (CUDA, PyTorch, Transformers). Запуск всего в одном окружении приведет к "dependency hell".

### Решение
Принято решение использовать **строгую изоляцию этапов** (Inference, Eval, Report) через контейнеризацию.
*   Каждый этап запускается в собственном изолированном окружении (Docker Container, Singularity, Pod).
*   Управление жизненным циклом окружений делегируется абстракции `EnvManager`.

### Последствия
*   **Плюсы**: Полная изоляция зависимостей. Возможность параллельного запуска разных моделей на одной машине. Легкая масштабируемость на кластер.
*   **Минусы**: Оверхед на запуск контейнеров. Необходимость управления передачей данных между этапами (через Shared FS или S3).

---

## ADR-002: Динамическая инъекция зависимостей (Just-In-Time Dependency Injection)

### Контекст
Создание отдельного Docker-образа под каждую комбинацию "Модель + Метрика" приведет к комбинаторному взрыву количества образов и сложности их поддержки.

### Решение
Использовать стратегию **базовых образов с динамической доустановкой пакетов**.
*   Поддерживается небольшое количество "толстых" базовых образов (Base GPU, Base CPU).
*   Специфичные для конкретной задачи или модели пакеты (драйверы, метрики) устанавливаются "на лету" при старте контейнера (через `uv pip install` или `pip`).

### Последствия
*   **Плюсы**: Гибкость. Минимальное количество поддерживаемых Docker-образов.
*   **Минусы**: Увеличение времени старта задачи (Cold Start) на время установки пакетов. Требуется доступ к PyPI (или локальному зеркалу) из контейнера.

---

## ADR-003: Использование API Wrapper для стандартизации инференса

### Контекст
Разные бэкенды (vLLM, SGLang, HF) предоставляют разные API и метрики. Нам нужен унифицированный способ получения ответов и метрик производительности (TTFT, Latency, Memory).

### Решение
Разработать легковесный **Inference API Wrapper** (на базе FastAPI).
*   Обертка запускается внутри контейнера с моделью.
*   Предоставляет единый API (`/v1/chat/completions`).
*   Измеряет метрики производительности "на месте" и обогащает ими ответ.

### Последствия
*   **Плюсы**: Унификация интерфейса для Оркестратора. Точные метрики производительности. Возможность легкой замены бэкенда.
*   **Минусы**: Небольшой оверхед на сериализацию/десериализацию (некритично для VLM).

---

## ADR-004: Гибридная стратегия доступа к данным (Smart Sync)

### Контекст
Модели требуют быстрого доступа к изображениям. При работе в кластере чтение данных по сети (S3) каждым воркером может создать узкое место (Network I/O bound).

### Решение
Использовать гибридный подход **"Sync-before-Run"**.
*   **Single-Node**: Использование локальных Volume Mounts (Bind Mounts).
*   **Multi-Node**: Данные хранятся в S3 (Source of Truth). Перед запуском задачи `EnvManager` синхронизирует (кэширует) необходимый датасет на локальный диск узла.

### Последствия
*   **Плюсы**: Высокая скорость чтения во время инференса (Local Disk I/O). Масштабируемость.
*   **Минусы**: Задержка перед стартом на скачивание данных (амортизируется при больших батчах). Требуется место на диске воркеров.

---

## ADR-005: Абстракция через Реестры (Everything is a Registry)

### Контекст
Фреймворк должен быть расширяемым. Пользователи должны иметь возможность добавлять свои модели, метрики и типы задач без изменения ядра системы.

### Решение
Использовать паттерн **Registry** для всех сущностей:
*   `ModelRegistry`: Конфигурации моделей.
*   `TaskRegistry`: Определения задач (формат данных, промпты).
*   `MetricRegistry`: Реализации метрик.
*   Реализации оформляются как отдельные Python-пакеты (плагины).

### Последствия
*   **Плюсы**: Высокая модульность и расширяемость. Четкое разделение ответственности.
*   **Минусы**: Повышение порога входа для разработчиков новых плагинов (нужно соблюдать интерфейсы).