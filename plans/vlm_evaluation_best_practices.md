# Лучшие практики оценки VLM (Best Practices)

## 1. Методология оценки
Оценка VLM сложнее, чем LLM, так как требует проверки понимания визуального контента, а не только генерации текста.

### 1.1. Категории задач
*   **Perception (Восприятие)**: Распознавание объектов, текста (OCR), атрибутов.
    *   *Бенчмарки*: VQAv2, DocVQA, OCRBench.
*   **Reasoning (Рассуждение)**: Логические выводы на основе изображения (MathVista, MMMU).
*   **Hallucination (Галлюцинации)**: Проверка на выдуманные объекты (POPE).

### 1.2. Подходы к генерации ответов
*   **Zero-shot**: Оценка без примеров (наиболее частый сценарий для VLM).
*   **Few-shot**: Добавление примеров (in-context learning) для сложных задач.
*   **Chain-of-Thought (CoT)**: Просьба модели "подумать пошагово" перед ответом (особенно для Math/Reasoning).

## 2. Метрики оценки
Метрики делятся на детерминированные (для закрытых задач) и семантические (для открытых).

### 2.1. Детерминированные метрики
*   **Exact Match (EM)**: Полное совпадение (после нормализации). Подходит для Multiple Choice.
*   **ANLS (Average Normalized Levenshtein Similarity)**: Стандарт де-факто для DocVQA и OCR задач. Устойчив к мелким опечаткам.
    *   *Формула*: `1 - d(pred, gt) / max(len(pred), len(gt))`, с порогом (обычно 0.5).

### 2.2. Семантические метрики
*   **BLEU / CIDEr / SPICE**: Традиционные метрики для Image Captioning. Измеряют n-gram перекрытия.
*   **LLM-as-a-Judge**: Использование сильной LLM (GPT-4) для оценки корректности ответа VLM.
    *   *Плюсы*: Понимает синонимы и перефразирования.
    *   *Минусы*: Дорого, зависит от "судьи".

## 3. Рекомендации для VLMHyperBench

### 3.1. Нормализация текста
Критически важна перед сравнением.
*   Приведение к нижнему регистру.
*   Удаление пунктуации.
*   Конвертация чисел (слова в цифры).

### 3.2. Closed-Set Evaluation Strategy
Для задач классификации документов:
*   Предоставлять список классов в промпте.
*   Использовать **shuffling** вариантов ответов, чтобы избежать позиционного смещения (positional bias).
*   Агрегировать результаты по частоте (majority voting) или лог-вероятностям (если API позволяет).

### 3.3. Модульность метрик
Реализовать метрики как отдельные классы с единым интерфейсом `Metric`, чтобы легко добавлять новые (например, ANLS для OCR).

### 3.4. Прозрачность
Сохранять не только итоговую метрику, но и **сырые предсказания** модели (`answers.csv`), чтобы можно было вручную проанализировать ошибки.