# Стратегия Абстракций и Обобщения VLMHyperBench

## 1. Философия
Фреймворк VLMHyperBench строится на принципе **инверсии зависимостей**. Ядро фреймворка не знает о конкретных моделях, типах задач или метриках. Оно оперирует абстракциями (интерфейсами), реализация которых инжектируется динамически через систему плагинов (пакетов).

Это позволяет использовать одну и ту же архитектуру для совершенно разных доменов:
*   Распознавание рукописного текста (OCR).
*   Детекция Deepfake на видео.
*   Анализ медицинских снимков (Medical VQA).
*   Аудио-анализ (Audio QA).

## 2. Ключевые Абстракции (Interfaces)

### 2.1. `Task` (Задача)
Определяет, **что** мы делаем с данными.
*   **Ответственность**:
    *   Определяет формат входных данных (Dataset Schema).
    *   Определяет стратегию формирования промпта (Prompt Strategy).
    *   Определяет формат ожидаемого ответа (Output Schema).
*   **Примеры реализации**:
    *   `DocumentVQA`: Вход - скан документа, Выход - JSON.
    *   `DeepfakeDetection`: Вход - видеофайл, Выход - вероятность фейка (0-1).
    *   `HandwrittenOCR`: Вход - кроп текста, Выход - строка.

### 2.2. `ModelInterface` (Модель)
Определяет, **как** мы получаем предсказание.
*   **Ответственность**:
    *   Загрузка весов (или инициализация клиента API).
    *   Препроцессинг входа (Image -> Tensor).
    *   Генерация (Inference).
*   **Методы**:
    *   `load(config, model_params: Dict[str, Any])`: Загрузка модели с передачей специфичных параметров (например, `temperature`, `max_new_tokens`, `use_flash_attn`).
    *   `predict(inputs: List[InputItem]) -> List[OutputItem]`
*   **Примеры реализации**:
    *   `Qwen2VL_HF`: Локальный инференс через Transformers.
    *   `GPT4o_API`: Вызов OpenAI API.
    *   `CustomDeepfakeModel`: Специфичная PyTorch модель.

### 2.3. `Metric` (Метрика)
Определяет, **как** мы оцениваем качество.
*   **Ответственность**:
    *   Сравнение `Prediction` и `GroundTruth`.
    *   Вычисление числового скора.
*   **Методы**:
    *   `compute(prediction, reference) -> float`
*   **Примеры реализации**:
    *   `ANLS`: Для OCR.
    *   `Accuracy`: Для классификации.
    *   `AUC-ROC`: Для детекции аномалий (Deepfake).

### 2.4. `ReportGenerator` (Отчет)
Определяет, **как** мы визуализируем результат.
*   **Ответственность**:
    *   Агрегация метрик.
    *   Построение графиков.
    *   Рендеринг финального документа.
*   **Примеры реализации**:
    *   `MarkdownReport`: Стандартный отчет.
    *   `ConfusionMatrixPlot`: Для классификации.

## 3. Реализация через Python-пакеты
Каждая конкретная реализация (например, поддержка новой задачи `DeepfakeDetection`) оформляется как отдельный Python-пакет, который:
1.  Реализует необходимые интерфейсы (`Task`, `Metric`).
2.  Регистрируется в системе (через `entry_points` или конфиг реестра).
3.  Устанавливается динамически в контейнер воркера.

### 3.1. Экосистема VLMHyperBench
1.  **Core (Абстракции)**: Минимальный набор интерфейсов (`vlmhyperbench-core`).
2.  **Plugins (Реализации)**:
    *   `vlmhyperbench-ocr`: Реализует `Task` для OCR и `Metric` (ANLS).
    *   `vlmhyperbench-deepfake`: Реализует `Task` для видео и `Metric` (AUC).
    *   `vlmhyperbench-medical`: Специфичные метрики и лоадеры DICOM.
3.  **Docker Images (Среда)**:
    *   `base-gpu`: CUDA, Torch, vLLM (тяжелые зависимости).
    *   `base-cpu`: Numpy, Pandas, Sklearn (для метрик).
    *   *Динамика*: При запуске в `base-gpu` доустанавливается `vlmhyperbench-ocr`.

## 4. Пайплайн (Pipeline Composition)
Пользователь в конфиге `user_config.csv` просто "собирает конструктор":
```csv
task,model,metric,dataset
DeepfakeDetection,DeepfakeResNet50,AUC-ROC,CelebDF
```
Оркестратор видит эти названия, находит соответствующие пакеты в реестре, устанавливает их и запускает пайплайн, дергая унифицированные методы `predict()` и `compute()`.

**Итог**: Фреймворк становится универсальным движком исполнения (Execution Engine) для любых задач, сводимых к схеме "Вход -> Модель -> Выход -> Сравнение с эталоном".