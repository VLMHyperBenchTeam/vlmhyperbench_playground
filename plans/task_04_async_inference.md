# Задача 4: Асинхронный Inference Loop

## Цель
Перевести основной скрипт исполнения `run_vlm.py` на асинхронную модель работы для повышения пропускной способности и утилизации ресурсов.

## Контекст
Текущая реализация `run_vlm.py` работает синхронно: загружает изображение, отправляет запрос, ждет ответа, сохраняет. При использовании внешних API или локального сервера модели это создает простои.
Асинхронность позволит отправлять пакеты запросов параллельно (контролируемая конкурентность).

## Подзадачи

1.  **Async HTTP Client** ✅ ВЫПОЛНЕНО:
    *   Реализован класс `AsyncModelClient` в `packages/api_wrapper/src/api_wrapper/client.py` на базе `httpx`.
    *   Добавлены Unit-тесты в `packages/api_wrapper/tests/test_client.py`.

2.  **Рефакторинг `run_vlm.py`** ✅ ВЫПОЛНЕНО:
    *   Скрипт `VLMHyperBench/vlmhyperbench/system_dirs/bench_stages/run_vlm.py` полностью переведен на `asyncio`.
    *   Используется `asyncio.Semaphore` для контроля конкурентности (через `CONCURRENCY` env).

3.  **Интеграция PromptManager** ✅ ВЫПОЛНЕНО:
    *   Внедрен `PromptManager` для динамического разрешения промптов в функции `process_item`.

4.  **Обработка ошибок и Retry** ✅ ВЫПОЛНЕНО:
    *   В `AsyncModelClient` реализована логика повторных попыток с экспоненциальной задержкой.

## Ожидаемый результат
*   [x] Скрипт `run_vlm.py` взаимодействует с API Wrapper асинхронно.
*   [x] Обработка датасета происходит параллельно с учетом ограничений семафора.
*   [x] Повышена надежность за счет системы ретраев.