# Отчет по исследованию для VLMHyperBench

Этот отчет обобщает результаты исследований, проведенных для проектирования архитектуры прототипа VLMHyperBench.

## 1. Архитектура и Развертывание
*   **Документ**: `plans/architecture_design.md`
*   **Ключевые выводы**:
    *   Утверждена микропакетная архитектура с изоляцией через Docker/Singularity.
    *   Внедрена концепция **EnvManager** для абстракции среды выполнения (Docker, Pod, venv).
    *   Разработана стратегия **динамической установки зависимостей**, позволяющая гибко настраивать окружение под конкретные этапы (Inference, Eval) без пересборки базовых образов.

## 2. Интеграция HuggingFace и vLLM
*   **Документ**: `plans/vlm_integration_research.md`
*   **Ключевые выводы**:
    *   Необходима абстракция `ModelInterface` для унификации API.
    *   **HuggingFace**: Используется для максимальной совместимости и отладки. Требует ручного управления процессорами изображений.
    *   **vLLM**: Используется для production-инференса (высокая скорость, batching). Требует специфичного форматирования `multi_modal_data`.
    *   Рекомендовано добавить поле `backend` в конфигурацию модели для выбора движка.

## 3. Анализ EvalScope
*   **Документ**: `plans/evalscope_architecture_research.md`
*   **Ключевые выводы**:
    *   EvalScope использует реестровую систему и адаптеры, что подтверждает правильность нашего выбора в пользу модульности.
    *   Использование существующих бэкендов (VLMEvalKit) — валидная стратегия.
    *   VLMHyperBench отличается более строгой изоляцией (контейнеризация каждого этапа) и специализацией на документарных задачах.

## 4. Лучшие практики оценки VLM
*   **Документ**: `plans/vlm_evaluation_best_practices.md`
*   **Ключевые выводы**:
    *   **ANLS** — критически важная метрика для OCR/DocVQA задач.
    *   Необходима тщательная **нормализация текста** перед сравнением.
    *   Для задач классификации рекомендуется использовать **Closed-Set Evaluation** с перемешиванием вариантов ответов.
    *   Важно сохранять сырые данные (`answers.csv`) для анализа ошибок.
    *   **Многоуровневая агрегация**: Реализовать подсчет метрик на трех уровнях:
        1.  Global (весь датасет).
        2.  Document Type (по типам документов).
        3.  Field Level (по конкретным полям извлечения).
    *   **Управление задачами и метриками**: Внедрить реестры `TaskRegistry` и `MetricRegistry` для гибкого добавления новых типов задач и метрик.
    *   **Промпт-инжиниринг**: Интеграция с системами версионирования промптов (Arize Phoenix) для трекинга экспериментов.
    *   **Масштабирование**: Асинхронный запуск и распараллеливание задач по нескольким GPU.

## 5. Итоговая рекомендация
Приступать к реализации прототипа, основываясь на утвержденном архитектурном плане (`architecture_design.md`) и используя разработанные стратегии интеграции (`vlm_integration_research.md`) и оценки (`vlm_evaluation_best_practices.md`).