# Задача 17: Стратегия Тестирования (Testing Strategy)

## Цель
Обеспечить надежность работы всех компонентов системы (от парсинга конфигов до запуска Docker-контейнеров) через многоуровневое тестирование.

## Контекст
VLMHyperBench — сложная распределенная система, управляющая Docker-контейнерами. Ошибки могут возникать на уровне конфигурации, инференса, оценки или инфраструктуры. Нам нужны тесты, которые покрывают как отдельные модули, так и весь пайплайн целиком.

## Уровни Тестирования

### 1. Unit Tests (Pytest)
**Цель**: Проверка логики отдельных классов и функций в изоляции.
**Что тестируем**:
*   `UserConfigReader`, `TaskRegistry` (парсинг YAML, валидация Pydantic).
*   `PromptResolver` (корректность выбора шаблона).
*   `MetricEvaluator` (расчет метрик на фиксированных данных).
*   `DependencyInjector` (генерация команд установки).
**Инструменты**: `pytest`.
**Принципы**:
*   Минимум моков. Используем реальные объекты там, где это возможно.
*   Моки (`pytest-mock`) применяются только для еще не реализованных компонентов или внешних систем (S3, если нет доступа).

### 2. Integration Tests (Docker Mock)
**Цель**: Проверка взаимодействия компонентов на реальных (но небольших) данных.
**Что тестируем**:
*   Взаимодействие `Orchestrator` -> `Backend`.
*   Запуск контейнеров через `Orchestrator` (используя легковесные образы `python:3.10-slim` вместо GPU-образов).
*   Проверка монтирования томов и передачи переменных окружения.
**Инструменты**: Локальный Docker, реальные модели (на CPU или GPU, если доступно), мини-датасеты (3-5 объектов).

### 3. End-to-End Tests (Pipeline Validation)
**Цель**: Проверка полного цикла работы системы.
**Сценарий (`demo_mini`)**:
1.  Запуск `vlm-orchestrator` и `vlm-backend` (локально или в CI).
2.  Отправка `ExperimentPlan` с одной задачей (реальная модель + реальный мини-датасет).
3.  Ожидание завершения.
4.  Проверка наличия `report.md` и корректности метрик.
**Инструменты**: Скрипты на Python/Bash.
**Локальный запуск**: Разработчик запускает тесты локально (с GPU) перед созданием PR.

### 4. Component Testing (Isolated Containers)
**Цель**: Проверка корректности работы образов и окружений.
**Сценарий**:
*   Запуск контейнера `vlm-base-hf`.
*   Установка пакетов через `DependencyInjector`.
*   Запуск `run_vlm.py` в режиме "dry-run" (без загрузки весов).

## План Реализации

1.  **Настройка CI/CD (GitHub Actions)**:
    *   Запуск Unit Tests при каждом PR.
    *   Linter (Ruff/Black) и Type Checker (MyPy).
    *   Ограничение: CI запускает тесты только на CPU. Тесты с GPU помечаются `@pytest.mark.gpu` и пропускаются в CI.
    *   **Self-Hosted Runner**: Для тестов с GPU можно подключить локальную машину разработчика как self-hosted runner к репозиторию GitHub (Settings -> Actions -> Runners). Это позволит запускать полные E2E тесты автоматически.

2.  **Local Testing Pipeline**:
    *   Скрипт `run_tests_local.sh`, который запускает полный набор тестов (включая GPU) на машине разработчика.

3.  **Smoke Tests**:
    *   Создать набор минимальных конфигов (`smoke_test_vqa.yaml`), которые проходят за <1 минуту.

## Ожидаемый результат
*   Покрытие кода тестами > 80%.
*   Автоматическая проверка работоспособности при изменениях.
*   Гарантия того, что Docker-контейнеры запускаются с правильными параметрами.