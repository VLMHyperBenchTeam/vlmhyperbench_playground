# Архитектурный план VLMHyperBench v0.2.0

Этот план описывает обновленную структуру модулей и методов для проведения оценки моделей Qwen3-VL 4b и DeepSeek-OCR 3b. Основной упор сделан на асинхронность, расширяемость через специфичные настройки и гибкое управление промптами.


## Docker образы (Фиксация версий)

Для обеспечения воспроизводимости мы используем конкретные теги образов:

*   **Hugging Face (Custom)**: Собираем свой образ `vlmhyperbench/vlm-base-hf:cu124-py310-torch2.5`.
    *   *Основа*: `nvidia/cuda:12.6.3-devel-ubuntu22.04`


### Обновление vLLM
*   **Текущая стабильная версия:** `vllm/vllm-openai:v0.14.0`
*   **Рекомендуемые теги:**
    *   `vllm/vllm-openai:v0.14.0` (OpenAI-совместимый)
    *   `vllm/vllm-openai:v0.14.0-cu130` (для CUDA 13.0)
*   **Ключевые особенности v0.14.0:**
    *   Включено асинхронное планирование (**Async scheduling**) по умолчанию.
    *   Требуется **PyTorch 2.9.1**.
    *   Добавлена нативная поддержка моделей **Qwen3**.

### Обновление SGLang
*   **Текущая стабильная версия:** `lmsysorg/sglang:v0.5.3`
*   **Рекомендуемые теги:**
    *   `lmsysorg/sglang:v0.5.3`
    *   `lmsysorg/sglang:v0.5.3-cu126` (для систем с CUDA 12.6)
*   **Ключевые особенности v0.5.x:**
    *   Переход на интенсивный цикл релизов (каждые 2–3 недели).
    *   Улучшенная поддержка мультимодальных моделей (**SGLang Diffusion**).
    *   Оптимизация работы на CPU.

### Сводная таблица актуальных версий

| Проект | Исходная версия | Актуальная версия (Январь 2026) | Рекомендуемый Docker-образ |
| :--- | :--- | :--- | :--- |
| **vLLM** | `v0.7.2` | `v0.14.0` | `vllm/vllm-openai:v0.14.0` |
| **SGLang** | `v0.4.1` | `v0.5.3` | `lmsysorg/sglang:v0.5.3` |

> [!TIP]
> Для получения самых последних исправлений можно использовать теги `nightly` (например, `vllm/vllm-openai:nightly`), но для стабильных рабочих сред рекомендуется использовать фиксированные версии, указанные в таблице.

## 6. План действий (Todo)

1.  [ ] Создать `packages/prompt_manager` для реализации логики выбора промптов.
2.  [ ] Реализовать `APIWrapper` (FastAPI) с поддержкой `model_params`.
3.  [ ] Подготовить `DeepSeekAdapter` с поддержкой специфичных для OCR настроек.
4.  [ ] Обновить `run_vlm.py` для асинхронной работы с `PromptManager`.
5.  [ ] Протестировать на `demo_mini` с маппингом промптов для разных типов документов.
